{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "MNIST for Tensorflow-lite\n",
    "----\n",
    "\n",
    "This notebook is part of this [post](https://www.stupid-projects.com/machine-learning-on-embedded-part-3) which is part a series of post about using ML and NN in embedded MCUs. The first post of the series is [here](https://www.stupid-projects.com/machine-learning-on-embedded-part-1)\n",
    "\n",
    "This notebook is just a port of [this](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.1-introduction-to-convnets.ipynb) notebook from Keras to TF.\n",
    "\n",
    "This notebook is meant to be used to train the MNIST NN and then export the model to TF-Lite for microcontrollers and uploaded to a stm32f746. Later there's a cell in the notebook that you can hand-draw a number on a window and then evaluate the model on both the notebook and the stm32f746 by running the inference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create the model\n",
    "\n",
    "As it's mentioned before, this is just a port from Keras to TF of [this](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.1-introduction-to-convnets.ipynb) notebook. For the model training we're going to use `convnets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpdz/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jpdz/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jpdz/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jpdz/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jpdz/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jpdz/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version 1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpdz/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jpdz/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jpdz/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jpdz/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jpdz/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jpdz/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "Labels: 10\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
    "print(train_labels.shape)\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "print(train_labels.shape)\n",
    "print(\"Labels:\", len(train_labels[0]))\n",
    "print(train_images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert train and test data\n",
    "Normally when the dataset is loaded the shape is (x, 28, 28). For convnets you need to reshape the data to (x, 28, 28, y), where `x` is the number of images per set and `y` in this case is the number of colors. Normally, of RGB it should be 3, but since the images are grayscale then it's 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: <class 'numpy.ndarray'>\n",
      "Dataset shape: (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data type:\", type(train_images))\n",
    "print(\"Dataset shape:\", (train_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: 60000\n",
      "Possible values: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels:\", len(train_labels))\n",
    "print(\"Possible values:\", np.unique(train_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print a digit from the dataset\n",
    "Now we just print a digit from the dataset in order to see how it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(img):\n",
    "    img = np.array(img, dtype='float')\n",
    "    pixels = img.reshape((28, 28))\n",
    "    plt.figure()\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    plt.xlabel(\"Classification label: {}\".format(train_labels[0]))\n",
    "    plt.show()\n",
    "    print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "display_img(train_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=tf.nn.relu, input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 72s 1ms/sample - loss: 0.1446 - acc: 0.9637\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.1490 - acc: 0.9765\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 70s 1ms/sample - loss: 0.1859 - acc: 0.9750\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 72s 1ms/sample - loss: 0.2158 - acc: 0.9745\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 67s 1ms/sample - loss: 0.2151 - acc: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fea2e546dd8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 91us/sample - loss: 0.1450 - acc: 0.9818\n",
      "Test accuracy: 0.9818\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 87us/sample - loss: 0.1450 - acc: 0.9818\n",
      "Restored model, accuracy: 98.18%\n",
      "Restored model, loss: 0.14496431586372854\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n",
    "print(\"Restored model, loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert the model to tflite\n",
    "\n",
    "Now we need to export the model and save it in a `h5` file. Then we use the `TFLiteConverter` to convert the model to the flatbuffer tflite format.\n",
    "\n",
    "Normally, we should use quantization on the model as it's explained [here](https://www.tensorflow.org/lite/microcontrollers/build_convert#quantization), but for some reason in the current version I'm using (1.14) that doesn't work and when the model is loaded on the stm32f746, then I get this error:\n",
    "\n",
    "```\n",
    "Only float32, int16, int32, int64, uint8, bool, complex64 supported currently\n",
    "```\n",
    "\n",
    "This error comes from the `source/libs/tensorflow/lite/experimental/micro/simple_tensor_allocator.cc` file and the reason is that when the model is converted with `TFLiteConverter`, then the output is set to `kTfLiteInt8`, which means signed integer and that is not yet supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist-tflite.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: If you want to add post-quantization during conversion (which doesn't work yet), then you need to uncomment the line in the next code. Finally, the output of the next command is the size of the flatbuffer model in bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jpdz/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/jpdz/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/jpdz/.local/lib/python3.6/site-packages/tensorflow/lite/python/util.py:238: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/jpdz/.local/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 10 variables.\n",
      "INFO:tensorflow:Converted 10 variables to const ops.\n",
      "INFO:tensorflow:Froze 10 variables.\n",
      "INFO:tensorflow:Converted 10 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file('mnist-tflite.h5')\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "flatbuffer_size = open(\"mnist.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file('mnist-tflite.h5')\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "flatbuffer_size_quantized = open(\"mnist_quantized.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "#print('The size of the converted flatbuffer is: %d bytes' % flatbuffer_size)\n",
    "#print('The size of the quantized converted flatbuffer is: %d bytes' % flatbuffer_size_quantized) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get -qq install xxd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a header file from the tflite model\n",
    "Now that you have your tflite flatbuffer you can convert it to a header file\n",
    "in order to add it to your C++ code you need to run this command in bash in\n",
    "the `jupyter _notebook` folder.\n",
    "\n",
    "```sh\n",
    "xxd -i jupyter_notebook/mnist.tflite > source/src/inc/model_data.h\n",
    "```\n",
    "\n",
    "#### Note:\n",
    "In the `source/src/inc/model_data.h` you need to change this line:\n",
    "```cpp\n",
    "unsigned char jupyter_notebook_mnist_tflite[] = {\n",
    "```\n",
    "to this:\n",
    "```cpp\n",
    "const unsigned char jupyter_notebook_mnist_tflite[] = {\n",
    "```\n",
    "Otherwise it won't fit in the RAM and you'll get this error:\n",
    "```sh\n",
    "stm32f7-mnist-tflite.elf section `.bss' will not fit in region `RAM'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load model and interpreter\n",
    "\n",
    "To evaluate the hand-written digit in the notebook then you need to create an interpreter and then feed the image (or array) in the input. You can create that here and use it later in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tflite_mnist_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a9ac602e8c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minterpreter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtflite_mnist_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"== Input details ==\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tflite_mnist_model' is not defined"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_mnist_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", interpreter.get_input_details()[0]['name'])\n",
    "print(\"shape:\", interpreter.get_input_details()[0]['shape'])\n",
    "print(\"type:\", interpreter.get_input_details()[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", interpreter.get_output_details()[0]['name'])\n",
    "print(\"shape:\", interpreter.get_output_details()[0]['shape'])\n",
    "print(\"type:\", interpreter.get_output_details()[0]['dtype'])\n",
    "\n",
    "print(\"\\nDUMP INPUT\")\n",
    "print(interpreter.get_input_details()[0])\n",
    "print(\"\\nDUMP OUTPUT\")\n",
    "print(interpreter.get_output_details()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
